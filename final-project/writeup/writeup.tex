\documentclass[conference]{IEEEtran}

\input{../../utils/header_final.tex}

\begin{document}

\title{Machine Learning Final Project}
\author{
\IEEEauthorblockN{William Clark}
\IEEEauthorblockA{will.clark@chicagobooth.edu\\
University of Chicago Booth School of Business}
\and
\IEEEauthorblockN{Matthew DeLio}
\IEEEauthorblockA{mdelio@chicagobooth.edu\\
University of Chicago Booth School of Business}}

\maketitle

\section{Summary}

\section{Modelling}
\subsection{Facial Keypoints Introduction}
\subsection{Building a Model (Tools \& Software)}


\subsection{Initial Models}
What we tried in a nutshell:
\begin{enumerate}
\item 3-level - 1 convolutional, 2 dense
\item 6-level - 3 convolutional, 3 dense
\item 6-level with dropout
\item Batchsize changes - positively correlated with minimum loss-floor.
\item Varying learning rate/momentum (static, and dynamic \cite{lasagnenesterov})
\item Wider layers
\item More/Less Dropout
\end{enumerate}

\subsection{Individual Feature Models}
Dropout, l1/l2 regularization, and momentum/learning rate.

Using the advice given in Andrew Ng's paper on regularization \cite{ng2004feature}, by acknowledging the fact that we have a dimensionally large input data-set, we choose to apply L1 regularization.

\subsection{Missing Feature Model}
Since the data contain many missing features caused by partially obscured images, our resulting model must also predict the presence of features.  To predict this we turn to a slightly modified version with a sigmoid non-linearity on the output layer and the binary cross-entropy loss function defined in \cref{eq:bin_cross}.

\[\label{eq:bin_cross}
 L = -target \log(p) - (1 - target) \log(1 - p)
\]

For many of the features, the neural network does a good job separating the classes and producing probabilities that make logical sense.  The ones that it doesn't separate well, like \texttt{Left Eye Center}, \texttt{Right Eye Center} and \texttt{Mouth Center Bottom Lip}, have few missing data-point exemplars in the training data (7, 9, 22 respectively out of 4934).

\begin{figure}[!ht]
  \centering
  \caption{Boxplots for Missing Eye Features}
  \includegraphics[scale=.5]{logistic_boxplots_eye.pdf}
  \label{fig:logistic_boxplots_eye}
\end{figure}

\begin{figure}[!ht]
  \centering
  \caption{Boxplots for Missing Eyebrow Features}
  \includegraphics[scale=.5]{logistic_boxplots_eyebrow.pdf}
  \label{fig:logistic_boxplots_eyebrow}
\end{figure}

\begin{figure}[!ht]
  \centering
  \caption{Boxplots for Missing Mouth Features}
  \includegraphics[scale=.5]{logistic_boxplots_mouth.pdf}
  \label{fig:logistic_boxplots_mouth}
\end{figure}

% \begin{figure}[!ht]
%   \centering
%   \caption{Boxplots for Missing Nose Feature}
%   \includegraphics[scale=.5]{logistic_boxplots_nose.pdf}
%   \label{fig:logistic_boxplots_nose}
% \end{figure}

With the output trained, we next turn to determining the optimal cutoff.  Using the R package \texttt{OptimalCutpoints} we choose to maximize the accuracy area \cite{lewis2008use,greiner1995two,greiner1996two} which is defined in \cref{eq:roc_aa}.

\[\label{eq:roc_aa}
AA(c)=\frac{TP(c)TN(c)}{(TP(c)+FN(c))(FP(c)+TN(c))}
\]
where $TP$ = True Positives, $TN$ = True Negatives, $FN$ = False Negatives, \& $FP$ = False Positives

Looking over our boxplots, we see there are generally two categories of features: those that are missing often and those that are not.  For the ones that are missing often, we have a relatively good separability between the predicted probabilities.  For those that are not, the separately is questionable at best.  Turning to the ROC plot for a feature that is missing quite often, \texttt{Left Eye Inner Corner}, (see \cref{fig:roc_left_eye_inner_corner}) we see there is a lot of area under the ROC curve and the optimal cutoff point of 0.5 seems to put us right on the upper-left edge of the curve.  Next, looking at \texttt{Left Eye Center}, a feature with few missing exemplars, (see \cref{fig:roc_left_eye_center}) we see less area and a clear trade-off between specificity and sensitivity.  Again, a value of 0.5 seems to put us on the upper-left edge of the curve.

It turns out that, given the optimization condition, the best cutoff for all of these features is 0.5 (see \cref{tab:logistic_cutoff_table}\footnote{Note: that the \texttt{Nose Tip} feature is present in all training and validation images.}).  In each of the cases, we end up with quite a large sensitivity and a reasonable specificity.

\begin{figure}[!htb]
  \centering
  \caption{ROC Curve for Left Eye Inner Corner}
  \includegraphics[scale=.5]{roc_left_eye_inner_corner.pdf}
  \label{fig:roc_left_eye_inner_corner}
\end{figure}

\begin{figure}[!htb]
  \centering
  \caption{ROC Curve For Left Eye Center Feature}
  \includegraphics[scale=.5]{roc_left_eye_center.pdf}
  \label{fig:roc_left_eye_center}
\end{figure}


\input{logistic_cutoff_table.tex}

\subsection{Combined Loss Model}
Semi-failed attempt to train missing signals and coordinates simultaneously.
\subsection{Putting It All Together}
Show examples

\section{Kaggle Submission}
Ranking?

\section{Applications}
\begin{enumerate}
\item Engagement Detection
\end{enumerate}

\medskip

\bibliographystyle{IEEEtran}
% \bibliographystyle{unsrt}
\bibliography{citations}

\end{document}

% \input{.tex}

% \begin{figure}[!htb]
%   \centering
%   \begin{subfigure}[b]{0.49\textwidth}
%     \caption{}
%     \includegraphics[width=\textwidth]{.pdf}
%     \label{fig:}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}[b]{0.49\textwidth}
%     \caption{}
%     \includegraphics[width=\textwidth]{.pdf}
%     \label{fig:}
%   \end{subfigure}
%   \caption{}
% \end{figure}

% \begin{figure}[!htb]
%   \centering
%   \caption{}
%   \includegraphics[scale=.5]{.pdf}
%   \label{fig:}
% \end{figure}